{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import codecs\n",
    "from itertools import chain\n",
    "import nltk\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "\n",
    "#pip install python-crfsuite\n",
    "\n",
    "import pycrfsuite\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_location = \"../data/intent_queries.json\"\n",
    "file_stream = codecs.open(file_location, 'r', 'utf-8')\n",
    "jdata = json.load(file_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "wnl = nltk.WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    tokens = wnl.lemmatize(t.lower(),pos='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(jdata, inp_intent = []):\n",
    "    data_List = []\n",
    "    if inp_intent == []:\n",
    "        intent_keys = jdata.keys()\n",
    "    else:\n",
    "        intent_keys = inp_intent\n",
    "    \n",
    "    print(intent_keys)\n",
    "    for intent in intent_keys:\n",
    "        for data in jdata[intent]:\n",
    "\n",
    "            wordList=[]\n",
    "            tagList=[]\n",
    "            posList=[]\n",
    "            sentlist=[]\n",
    "\n",
    "            for sequence in data['data']:   \n",
    "                text = sequence['text'].lower()\n",
    "                tokens = nltk.word_tokenize(text)\n",
    "                tokens=[ wnl.lemmatize(t.lower(),pos='v') for t in tokens]\n",
    "                text=\" \".join(tokens)\n",
    "                tokenList = text.split()\n",
    "\n",
    "                if 'entity' not in sequence:\n",
    "                    for tok in tokenList:\n",
    "                        wordList.append(tok)\n",
    "                        tagList.append('O')\n",
    "                else:\n",
    "                    for idx,tok in enumerate(tokenList):\n",
    "                        wordList.append(tok)\n",
    "                        if idx:\n",
    "                            tagList.append('I-'+sequence['entity']) #entity token\n",
    "                        else:\n",
    "                            tagList.append('B-'+sequence['entity'])\n",
    "\n",
    "            sent = ' '.join(wordList)\n",
    "            sent_nlp = nlp(sent) #POS tag\n",
    "\n",
    "            for token in sent_nlp:\n",
    "                posList.append(token.tag_) #retrieve tag\n",
    "\n",
    "            for idx,word in enumerate(wordList):\n",
    "                sentlist.append((word,posList[idx],tagList[idx]))\n",
    "\n",
    "            data_List.append(sentlist)\n",
    "    return data_List\n",
    "\n",
    "def input_prep(text):\n",
    "    data_List = []\n",
    "\n",
    "    for sequence in text:\n",
    "        wordList=[]\n",
    "        posList=[]\n",
    "        tagList = []\n",
    "        sentlist=[]\n",
    "\n",
    "        text = sequence.strip().lower()\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        tokens=[ wnl.lemmatize(t.lower(),pos='v') for t in tokens]\n",
    "        text=\" \".join(tokens)\n",
    "        tokenList = text.split()\n",
    "\n",
    "        for tok in tokenList:\n",
    "            wordList.append(tok)\n",
    "            tagList.append('O')\n",
    "\n",
    "        sent = ' '.join(wordList)\n",
    "        sent_nlp = nlp(sent) #POS tag\n",
    "\n",
    "        for token in sent_nlp:\n",
    "            posList.append(token.tag_) #retrieve tag\n",
    "\n",
    "        for idx,word in enumerate(wordList):\n",
    "            sentlist.append((word,posList[idx],tagList[idx]))\n",
    "\n",
    "        data_List.append(sentlist)\n",
    "    return data_List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i): #function to create feature vector to represent each word\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "    features = [  # for all words\n",
    "        'bias',\n",
    "        'word.lower=' + word.lower(),\n",
    "        #'word[-3:]=' + word[-3:],\n",
    "        'word.isupper=%s' % word.isupper(),\n",
    "        'word.istitle=%s' % word.istitle(),\n",
    "        'word.isdigit=%s' % word.isdigit(),\n",
    "        'postag=' + postag,\n",
    "        'postag[:2]=' + postag[:2], #what is the POS tag for the next 2 word token\n",
    "    ]\n",
    "    if i > 0: # if not <S>\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.extend([\n",
    "            '-1:word.lower=' + word1.lower(),\n",
    "            '-1:word.istitle=%s' % word1.istitle(),\n",
    "            '-1:word.isupper=%s' % word1.isupper(),\n",
    "            '-1:word.isdigit=%s' % word1.isdigit(),\n",
    "            '-1:postag=' + postag1,\n",
    "            '-1:postag[:2]=' + postag1[:2],\n",
    "        ])\n",
    "    else:\n",
    "        features.append('BOS')  # beginning of statement\n",
    "        \n",
    "    if i < len(sent)-1:  # if not <\\S>\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.extend([\n",
    "            '+1:word.lower=' + word1.lower(),\n",
    "            '+1:word.istitle=%s' % word1.istitle(),\n",
    "            '+1:word.isupper=%s' % word1.isupper(),\n",
    "            '+1:word.isdigit=%s' % word1.isdigit(),\n",
    "            '+1:postag=' + postag1,\n",
    "            '+1:postag[:2]=' + postag1[:2],\n",
    "        ])\n",
    "    else:\n",
    "        features.append('EOS')\n",
    "                \n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['commonQ.assist', 'commonQ.how', 'commonQ.name', 'commonQ.wait', 'recommend.game', 'response.abusive', 'response.negative', 'response.incorrect', 'game.price', 'game.age', 'game.release_date', 'game.platforms', 'response.positive'])\n"
     ]
    }
   ],
   "source": [
    "train_list = loadData(jdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [sent2features(s) for s in train_list]\n",
    "Y_train = [sent2labels(s) for s in train_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "for xseq, yseq in zip(X_train, Y_train):\n",
    "    trainer.append(xseq, yseq)\n",
    "\n",
    "trainer.set_params({\n",
    "    'c1': 1.0,   # coefficient for L1 penalty\n",
    "    'c2': 1e-3,  # coefficient for L2 penalty\n",
    "    'max_iterations': 50,  # stop earlier\n",
    "\n",
    "    # include transitions that are possible, but not observed\n",
    "    'feature.possible_transitions': True\n",
    "})\n",
    "\n",
    "trainer.params()\n",
    "\n",
    "trainer.train('recommend_game.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x273a78b7a88>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('recommend_game.crfsuite')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['recommend.game', 'response.incorrect', 'game.price'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kewlg\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\kewlg\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-age       1.00      0.50      0.67         2\n",
      " B-character       1.00      0.67      0.80         6\n",
      "     B-genre       1.00      0.78      0.88         9\n",
      "     B-price       1.00      0.83      0.91         6\n",
      "     I-price       1.00      0.80      0.89         5\n",
      "\n",
      "   micro avg       1.00      0.75      0.86        28\n",
      "   macro avg       1.00      0.72      0.83        28\n",
      "weighted avg       1.00      0.75      0.85        28\n",
      " samples avg       0.23      0.23      0.23        28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testfile_location = \"../data/test_queries.json\"\n",
    "testfile_stream = codecs.open(testfile_location, 'r', 'utf-8')\n",
    "testjdata = json.load(testfile_stream)\n",
    "\n",
    "test_list = loadData(testjdata)\n",
    "\n",
    "X_test = [sent2features(s) for s in test_list]\n",
    "Y_test = [sent2labels(s) for s in test_list]\n",
    "\n",
    "###################################################################\n",
    "def bio_classification_report(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Classification report for a list of BIO-encoded sequences.\n",
    "    It computes token-level metrics and discards \"O\" labels.\n",
    "    \n",
    "    Note that it requires scikit-learn 0.15+ (or a version from github master)\n",
    "    to calculate averages properly!\n",
    "    \"\"\"\n",
    "    lb = LabelBinarizer()\n",
    "    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
    "    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
    "        \n",
    "    tagset = set(lb.classes_) - {'O'}\n",
    "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
    "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
    "    \n",
    "    return classification_report(\n",
    "        y_true_combined,\n",
    "        y_pred_combined,\n",
    "        labels = [class_indices[cls] for cls in tagset],\n",
    "        target_names = tagset,\n",
    "    )\n",
    "\n",
    "Y_pred = [tagger.tag(xseq) for xseq in X_test]\n",
    "print(bio_classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('i', 'PRP', 'O'),\n",
       "  ('be', 'VBP', 'O'),\n",
       "  ('10', 'CD', 'B-age'),\n",
       "  ('years', 'NNS', 'I-age'),\n",
       "  ('old', 'JJ', 'I-age'),\n",
       "  ('and', 'CC', 'O'),\n",
       "  ('look', 'VBP', 'O'),\n",
       "  ('for', 'IN', 'O'),\n",
       "  ('free', 'JJ', 'B-price'),\n",
       "  ('shoot', 'NN', 'B-genre'),\n",
       "  ('game', 'NN', 'O'),\n",
       "  ('with', 'IN', 'O'),\n",
       "  ('zombies', 'NNS', 'B-character'),\n",
       "  ('.', '.', 'O'),\n",
       "  ('can', 'MD', 'O'),\n",
       "  ('you', 'PRP', 'O'),\n",
       "  ('recommend', 'VB', 'O')],\n",
       " [('i', 'PRP', 'O'),\n",
       "  ('be', 'VBP', 'O'),\n",
       "  ('look', 'VB', 'O'),\n",
       "  ('for', 'IN', 'O'),\n",
       "  ('kill', 'NN', 'B-genre'),\n",
       "  ('game', 'NN', 'O'),\n",
       "  ('with', 'IN', 'O'),\n",
       "  ('animals', 'NNS', 'B-character'),\n",
       "  ('for', 'IN', 'O'),\n",
       "  ('under', 'IN', 'B-price'),\n",
       "  ('$', '$', 'I-price'),\n",
       "  ('10', 'CD', 'I-price')],\n",
       " [('any', 'DT', 'O'),\n",
       "  ('action', 'NN', 'B-genre'),\n",
       "  ('game', 'NN', 'O'),\n",
       "  ('with', 'IN', 'O'),\n",
       "  ('animal', 'NN', 'B-character'),\n",
       "  ('under', 'IN', 'B-price'),\n",
       "  ('10', 'CD', 'I-price'),\n",
       "  ('buck', 'NN', 'I-price')],\n",
       " [('run', 'NN', 'B-genre'), ('game', 'NN', 'O')],\n",
       " [('airplane', 'NN', 'B-character'),\n",
       "  ('shoot', 'NN', 'B-genre'),\n",
       "  ('game', 'NN', 'O')],\n",
       " [('i', 'PRP', 'O'),\n",
       "  ('be', 'VBP', 'O'),\n",
       "  ('10', 'CD', 'B-age'),\n",
       "  ('and', 'CC', 'O'),\n",
       "  ('look', 'VB', 'O'),\n",
       "  ('for', 'IN', 'O'),\n",
       "  ('free', 'JJ', 'B-price'),\n",
       "  ('shoot', 'NN', 'B-genre'),\n",
       "  ('zombie', 'NN', 'B-character'),\n",
       "  ('game', 'NN', 'O'),\n",
       "  ('.', '.', 'O'),\n",
       "  ('can', 'MD', 'O'),\n",
       "  ('you', 'PRP', 'O'),\n",
       "  ('recommend', 'VB', 'O')],\n",
       " [('any', 'DT', 'O'),\n",
       "  ('rpg', 'NN', 'B-genre'),\n",
       "  ('game', 'NN', 'O'),\n",
       "  ('that', 'WDT', 'O'),\n",
       "  ('be', 'VB', 'O'),\n",
       "  ('free', 'JJ', 'B-price'),\n",
       "  ('?', '.', 'I-price')],\n",
       " [('multi-player', 'JJ', 'B-genre'),\n",
       "  ('game', 'HYPH', 'O'),\n",
       "  ('shoot', 'NN', 'B-genre'),\n",
       "  ('monsters', 'NN', 'B-character'),\n",
       "  ('and', 'NN', 'O'),\n",
       "  ('free', 'NNS', 'B-price')],\n",
       " [('no', 'UH', 'O'),\n",
       "  ('this', 'DT', 'O'),\n",
       "  ('be', 'VB', 'O'),\n",
       "  ('not', 'RB', 'O'),\n",
       "  ('what', 'WP', 'O'),\n",
       "  ('i', 'PRP', 'O'),\n",
       "  ('want', 'VBP', 'O')],\n",
       " [('not', 'RB', 'O'), ('right', 'JJ', 'O')],\n",
       " [('not', 'RB', 'O'),\n",
       "  ('what', 'WP', 'O'),\n",
       "  ('i', 'PRP', 'O'),\n",
       "  ('want', 'VBP', 'O')],\n",
       " [('not', 'RB', 'O'), ('correct', 'JJ', 'O')],\n",
       " [('do', 'VBP', 'O'),\n",
       "  ('i', 'PRP', 'O'),\n",
       "  ('have', 'VB', 'O'),\n",
       "  ('to', 'TO', 'O'),\n",
       "  ('pay', 'VB', 'O')],\n",
       " [('must', 'MD', 'O'), ('pay', 'VB', 'O')]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test_list = test_list\n",
    "for idx_sent, sent in enumerate(Y_pred):\n",
    "    for idx_word, word in enumerate(sent):\n",
    "        if word != 'O' :\n",
    "            words = new_test_list[idx_sent][idx_word]\n",
    "            words = (words[0], words[1],word)\n",
    "            new_test_list[idx_sent][idx_word] = words\n",
    "new_test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "look for rpg game kill monster free\n",
      "['look for rpg game kill monster free']\n"
     ]
    }
   ],
   "source": [
    "#example_sent = \"I am 10 years old and looking for free shooting game with zombies. Can you recommend\"\n",
    "#example_sent = \"RPG game shooting monster\"\n",
    "example_sent = \"look for rpg game kill monster free\"\n",
    "example_sent_split = example_sent.replace(' and', '.').split('.')\n",
    "print(example_sent)\n",
    "print(example_sent_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('look', 'VB', 'O'), ('for', 'IN', 'O'), ('rpg', 'NN', 'O'), ('game', 'NN', 'O'), ('kill', 'NN', 'O'), ('monster', 'NN', 'O'), ('free', 'JJ', 'O')]]\n"
     ]
    }
   ],
   "source": [
    "cl_example_sent = input_prep(example_sent_split)\n",
    "print(cl_example_sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['bias', 'word.lower=look', 'word.isupper=False', 'word.istitle=False', 'word.isdigit=False', 'postag=VB', 'postag[:2]=VB', 'BOS', '+1:word.lower=for', '+1:word.istitle=False', '+1:word.isupper=False', '+1:word.isdigit=False', '+1:postag=IN', '+1:postag[:2]=IN'], ['bias', 'word.lower=for', 'word.isupper=False', 'word.istitle=False', 'word.isdigit=False', 'postag=IN', 'postag[:2]=IN', '-1:word.lower=look', '-1:word.istitle=False', '-1:word.isupper=False', '-1:word.isdigit=False', '-1:postag=VB', '-1:postag[:2]=VB', '+1:word.lower=rpg', '+1:word.istitle=False', '+1:word.isupper=False', '+1:word.isdigit=False', '+1:postag=NN', '+1:postag[:2]=NN'], ['bias', 'word.lower=rpg', 'word.isupper=False', 'word.istitle=False', 'word.isdigit=False', 'postag=NN', 'postag[:2]=NN', '-1:word.lower=for', '-1:word.istitle=False', '-1:word.isupper=False', '-1:word.isdigit=False', '-1:postag=IN', '-1:postag[:2]=IN', '+1:word.lower=game', '+1:word.istitle=False', '+1:word.isupper=False', '+1:word.isdigit=False', '+1:postag=NN', '+1:postag[:2]=NN'], ['bias', 'word.lower=game', 'word.isupper=False', 'word.istitle=False', 'word.isdigit=False', 'postag=NN', 'postag[:2]=NN', '-1:word.lower=rpg', '-1:word.istitle=False', '-1:word.isupper=False', '-1:word.isdigit=False', '-1:postag=NN', '-1:postag[:2]=NN', '+1:word.lower=kill', '+1:word.istitle=False', '+1:word.isupper=False', '+1:word.isdigit=False', '+1:postag=NN', '+1:postag[:2]=NN'], ['bias', 'word.lower=kill', 'word.isupper=False', 'word.istitle=False', 'word.isdigit=False', 'postag=NN', 'postag[:2]=NN', '-1:word.lower=game', '-1:word.istitle=False', '-1:word.isupper=False', '-1:word.isdigit=False', '-1:postag=NN', '-1:postag[:2]=NN', '+1:word.lower=monster', '+1:word.istitle=False', '+1:word.isupper=False', '+1:word.isdigit=False', '+1:postag=NN', '+1:postag[:2]=NN'], ['bias', 'word.lower=monster', 'word.isupper=False', 'word.istitle=False', 'word.isdigit=False', 'postag=NN', 'postag[:2]=NN', '-1:word.lower=kill', '-1:word.istitle=False', '-1:word.isupper=False', '-1:word.isdigit=False', '-1:postag=NN', '-1:postag[:2]=NN', '+1:word.lower=free', '+1:word.istitle=False', '+1:word.isupper=False', '+1:word.isdigit=False', '+1:postag=JJ', '+1:postag[:2]=JJ'], ['bias', 'word.lower=free', 'word.isupper=False', 'word.istitle=False', 'word.isdigit=False', 'postag=JJ', 'postag[:2]=JJ', '-1:word.lower=monster', '-1:word.istitle=False', '-1:word.isupper=False', '-1:word.isdigit=False', '-1:postag=NN', '-1:postag[:2]=NN', 'EOS']]]\n"
     ]
    }
   ],
   "source": [
    "x = [sent2features(s) for s in cl_example_sent]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['O', 'O', 'B-genre', 'O', 'B-genre', 'B-character', 'B-price']]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagList = [tagger.tag(s) for s in x]\n",
    "tagList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx_sent, sent in enumerate(tagList):\n",
    "    for idx_word, word in enumerate(sent):\n",
    "        if word != 'O' :\n",
    "            words = cl_example_sent[idx_sent][idx_word]\n",
    "            words = (words[0], words[2],word)\n",
    "            cl_example_sent[idx_sent][idx_word] = words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('look', 'VB', 'O'),\n",
       "  ('for', 'IN', 'O'),\n",
       "  ('rpg', 'O', 'B-genre'),\n",
       "  ('game', 'NN', 'O'),\n",
       "  ('shoot', 'O', 'B-genre'),\n",
       "  ('monster', 'O', 'B-character'),\n",
       "  ('free', 'O', 'B-price')]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl_example_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('look', 'VB', 'O')\n",
      "('for', 'IN', 'O')\n",
      "('rpg', 'O', 'B-genre')\n",
      "('game', 'NN', 'O')\n",
      "('shoot', 'O', 'B-genre')\n",
      "('monster', 'O', 'B-character')\n",
      "('free', 'O', 'B-price')\n"
     ]
    }
   ],
   "source": [
    "genreList = []\n",
    "priceList = []\n",
    "ageList = []\n",
    "for idx_sent, sent in enumerate(cl_example_sent):\n",
    "    for idx_word, word in enumerate(sent):\n",
    "        print(word)\n",
    "        if 'genre' in word[2]:\n",
    "            genreList.append(word[0])\n",
    "        elif 'age' in word[2]:\n",
    "            if word[0].isdigit():\n",
    "                ageList.append(word[0])\n",
    "        elif 'price' in word[2]:\n",
    "            if 'free' in word[0]:\n",
    "                priceList.append(0)\n",
    "            else:\n",
    "                if word[0].replace('$','').isdigit():\n",
    "                    priceList.append(int(word[0].replace('$','')))\n",
    "\n",
    "entitylist = {'genre': genreList, 'price': priceList, 'age': ageList}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'genre': ['rpg', 'shoot'], 'price': [0], 'age': []}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entitylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
