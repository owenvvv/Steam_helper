{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\envs\\tpml\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "from scipy.sparse import hstack\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display\n",
    "from string import punctuation\n",
    "from tqdm import tqdm_notebook\n",
    "from ipywidgets import FloatProgress\n",
    "\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, auc, roc_auc_score\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "norec = pd.read_csv('notrecommend.csv',low_memory=False)\n",
    "applist = pd.read_csv('small_steam_id.csv')\n",
    "rec_train = pd.read_csv('small_pos_review_cleaned.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>recommended</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>I never liked this game, nor I do now. I remem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Phew men that's my childhood right here.\\nDon'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>You are 14 years old, first time trying to pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>this is one of the first games i played as a k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>False</td>\n",
       "      <td>i do not recommend this game in 2019 as there ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id recommended                                               text\n",
       "0        10.0       False  I never liked this game, nor I do now. I remem...\n",
       "1        10.0       False  Phew men that's my childhood right here.\\nDon'...\n",
       "2        10.0       False  You are 14 years old, first time trying to pla...\n",
       "3        10.0       False  this is one of the first games i played as a k...\n",
       "4        20.0       False  i do not recommend this game in 2019 as there ..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norec_train=norec[['product_id','recommended','text']]\n",
    "norec_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46072, 3)\n",
      "appid         int64\n",
      "review       object\n",
      "sentiment     int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appid</th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>This old cs. Also like to play some times</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Classic game</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>ok</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>Good old Cs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>ALV</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   appid                                     review  sentiment\n",
       "0     10  This old cs. Also like to play some times          1\n",
       "1     10                               Classic game          1\n",
       "2     10                                         ok          1\n",
       "3     10                                Good old Cs          1\n",
       "4     10                                        ALV          1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_train=rec_train[['appid','review']]\n",
    "rec_train['sentiment'] = 1\n",
    "print(rec_train.shape)\n",
    "print(rec_train.dtypes)\n",
    "rec_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2971"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_norec=norec_train[norec_train['product_id'].isin(applist['appid'])]\n",
    "len(review_norec.product_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['recommended\\\\t'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-094f1d1c805c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mreview_norec\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'review'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreview\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mreview_norec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreview_norec\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'product_id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'review'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'recommended '\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mreview_norec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'product_id'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'appid'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreview_norec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tpml\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2999\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3000\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3001\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3002\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3003\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tpml\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[0;32m   1283\u001b[0m                 \u001b[1;31m# When setting, missing keys are not allowed, even with .loc:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1284\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"raise_missing\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mis_setter\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1285\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1286\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tpml\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m         self._validate_read_indexer(\n\u001b[1;32m-> 1092\u001b[1;33m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1093\u001b[0m         )\n\u001b[0;32m   1094\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tpml\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1183\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"loc\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1184\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1185\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{} not in index\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnot_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m             \u001b[1;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['recommended\\\\t'] not in index\""
     ]
    }
   ],
   "source": [
    "review_norec = review_norec.dropna().reset_index(drop = True)\n",
    "review = []\n",
    "for i in range(len(review_norec)):\n",
    "    s = re.compile(r'[^A-Za-z0-9\\s\\-\\.\\/]',re.S)\n",
    "    if str(review_norec.loc[i]['text']) == 'nan':\n",
    "        review.append('')\n",
    "        continue\n",
    "    try:\n",
    "        review.append(s.sub('',review_norec.loc[i]['text']))\n",
    "    except TypeError as er:\n",
    "        print(review_norec.loc[i]['text'])\n",
    "        pass\n",
    "    \n",
    "review_norec['review'] = review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    58713\n",
      "True         1\n",
      "Name: recommended, dtype: int64\n",
      "<class 'bool'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appid</th>\n",
       "      <th>review</th>\n",
       "      <th>recommended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44394</th>\n",
       "      <td>469600.0</td>\n",
       "      <td>Its ok.\\nI wish they would re-implement the 4v...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          appid                                             review recommended\n",
       "44394  469600.0  Its ok.\\nI wish they would re-implement the 4v...        True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_norec = review_norec[['product_id','review','recommended']].dropna().reset_index(drop=True)\n",
    "review_norec.columns = ['appid','review','recommended']\n",
    "print(review_norec.shape)\n",
    "print(review_norec.isnull().sum())\n",
    "print(review_norec['recommended'].value_counts())\n",
    "print(type(review_norec.loc[0,'recommended']))\n",
    "review_norec.loc[review_norec['recommended']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    58713\n",
      "Name: recommended, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#review_norec = review_norec.rename(columns={'product_id':'appid'}).astype({'appid':'int64','recommended':'object'})\n",
    "review_norec = review_norec.loc[review_norec['recommended'] == False]\n",
    "print(review_norec['recommended'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58713, 3)\n",
      "appid         0\n",
      "review       60\n",
      "sentiment     0\n",
      "dtype: int64\n",
      "0    58713\n",
      "Name: sentiment, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appid</th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58709</th>\n",
       "      <td>1052070</td>\n",
       "      <td>This a really neat interactive story.\\nIt is a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58710</th>\n",
       "      <td>1052070</td>\n",
       "      <td>I mean... its pretty. but outside of that its ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58711</th>\n",
       "      <td>1052070</td>\n",
       "      <td>Heavy bad glitches just no.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58712</th>\n",
       "      <td>1052070</td>\n",
       "      <td>A vanity project for a graphic artist and musi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58713</th>\n",
       "      <td>1052070</td>\n",
       "      <td>I really wanted to like this game as it was ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         appid                                             review  sentiment\n",
       "58709  1052070  This a really neat interactive story.\\nIt is a...          0\n",
       "58710  1052070  I mean... its pretty. but outside of that its ...          0\n",
       "58711  1052070                        Heavy bad glitches just no.          0\n",
       "58712  1052070  A vanity project for a graphic artist and musi...          0\n",
       "58713  1052070  I really wanted to like this game as it was ma...          0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_norec['sentiment'] = 0\n",
    "review_norec = review_norec[['appid','review','sentiment']]\n",
    "print(review_norec.shape)\n",
    "print(review_norec.isnull().sum())\n",
    "print(review_norec['sentiment'].value_counts())\n",
    "review_norec.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appid        0\n",
      "review       0\n",
      "sentiment    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "review_norec.dropna(inplace=True)\n",
    "print(review_norec.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appid         int64\n",
      "review       object\n",
      "sentiment     int64\n",
      "dtype: object\n",
      "0    58653\n",
      "1    46072\n",
      "Name: sentiment, dtype: int64\n",
      "(104725, 3)\n",
      "appid        0\n",
      "review       0\n",
      "sentiment    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appid</th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104720</th>\n",
       "      <td>1052070</td>\n",
       "      <td>Its basically a walking simulator with limited...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104721</th>\n",
       "      <td>1052070</td>\n",
       "      <td>This is not a game it is a piece of artistic e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104722</th>\n",
       "      <td>1052070</td>\n",
       "      <td>Incredible game. It takes place in a cyberpunk...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104723</th>\n",
       "      <td>1052070</td>\n",
       "      <td>One of the best free game on Steam. Superb vis...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104724</th>\n",
       "      <td>1052070</td>\n",
       "      <td>Extremely interesting art game by 12 students ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          appid                                             review  sentiment\n",
       "104720  1052070  Its basically a walking simulator with limited...          1\n",
       "104721  1052070  This is not a game it is a piece of artistic e...          1\n",
       "104722  1052070  Incredible game. It takes place in a cyberpunk...          1\n",
       "104723  1052070  One of the best free game on Steam. Superb vis...          1\n",
       "104724  1052070  Extremely interesting art game by 12 students ...          1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "review_small = pd.concat([review_norec,rec_train],ignore_index=True)\n",
    "review_small.dropna(inplace=True)\n",
    "print(review_small.dtypes)\n",
    "print(review_small['sentiment'].value_counts())\n",
    "print(review_small.shape)\n",
    "print(review_small.isnull().sum())\n",
    "display(review_small.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83780, 2) (20945, 2) (83780,) (20945,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(pd.DataFrame(review_small[['review','sentiment']]), \n",
    "                                                    pd.Series(review_small['sentiment']),\n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=0)\n",
    "\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "SteamDocument = collections.namedtuple('SteamDocument','words tags split sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83780\n",
      "SteamDocument(words=['it', 'crashes', 'upon', 'start'], tags=[1], split='train', sentiment=0)\n"
     ]
    }
   ],
   "source": [
    "import gensim.utils\n",
    "Steam_train = []\n",
    "for i in range(len(x_train)):\n",
    "    tokens = gensim.utils.simple_preprocess(x_train.iloc[i][0])\n",
    "    Steam_train.append(SteamDocument(tokens, [i], 'train', x_train.iloc[i][1]))\n",
    "print(len(Steam_train))\n",
    "print(Steam_train[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20945\n",
      "SteamDocument(words=['finished', 'on', 'april', 'automatic', 'save', 'combat', 'mechanism', 'except', 'melee', 'graphics', 'weapons', 'can', 'be', 'upgraded', 'if', 'the', 'same', 'weapon', 'is', 'picked', 'on', 'the', 'field', 'characters', 'dialogs', 'quality', 'level', 'design', 'no', 'extra', 'objectives', 'side', 'quests', 'story', 'voice', 'acting'], tags=[1], split='test', sentiment=0)\n"
     ]
    }
   ],
   "source": [
    "Steam_test = []\n",
    "for i in range(len(x_test)):\n",
    "    tokens = gensim.utils.simple_preprocess(x_test.iloc[i][0])\n",
    "    Steam_test.append(SteamDocument(tokens, [i], 'test', x_test.iloc[i][1]))\n",
    "print(len(Steam_test))\n",
    "print(Steam_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104725"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldocs = Steam_train + Steam_test\n",
    "len(alldocs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from collections import OrderedDict\n",
    "\n",
    "import gensim.models.doc2vec\n",
    "assert gensim.models.doc2vec.FAST_VERSION > -1, \"This will be painfully slow otherwise\"\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(dbow,d100,n5,mc2,t12) vocabulary built and state initialized\n",
      "Doc2Vec(\"alpha=0.05\",dm/m,d100,n5,w10,mc2,t12) vocabulary built and state initialized\n",
      "Doc2Vec(dm/c,d100,n5,w5,mc2,t12) vocabulary built and state initialized\n"
     ]
    }
   ],
   "source": [
    "common_kwargs = dict(vector_size = 100, epochs = 40, min_count = 2,\n",
    "                    sample = 0, workers = multiprocessing.cpu_count(),\n",
    "                    negative = 5, hs = 0,)\n",
    "\n",
    "simple_models = [\n",
    "    #PV-DBOW\n",
    "    Doc2Vec(dm=0, **common_kwargs),\n",
    "    #PV-DM /average\n",
    "    Doc2Vec(dm=1, window=10, alpha=0.05, comment='alpha=0.05', **common_kwargs),\n",
    "    #PV-DM /concatenation\n",
    "    Doc2Vec(dm=1, dm_concat = 1, window = 5, **common_kwargs),\n",
    "]\n",
    "\n",
    "for model in simple_models:\n",
    "    model.build_vocab(alldocs)\n",
    "    print(\"%s vocabulary built and state initialized\" % model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_by_name = OrderedDict((str(model),model) for model in simple_models)\n",
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "models_by_name['dbow+dmm'] = ConcatenatedDoc2Vec([simple_models[0], simple_models[1]])\n",
    "models_by_name['dbow+dmc'] = ConcatenatedDoc2Vec([simple_models[0], simple_models[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define evaluate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import statsmodels.api as sm\n",
    "from random import sample\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "#from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "def svc_predictor_from_data(train_targets, train_regressors):\n",
    "    \"\"\"Fit a svc predictor on supplied data\"\"\"\n",
    "    clf = SVC(kernel='rbf',C=0.4,class_weight='balanced')\n",
    "    clf.fit(train_regressors, train_targets)\n",
    "#     logit = sm.Logit(train_targets, train_regressors)\n",
    "#     predictor = logit.fit(disp=0)\n",
    "    # print(predictor.summary())\n",
    "    return clf\n",
    "\n",
    "def error_rate_for_model(test_model, train_set, test_set, test_target):\n",
    "    \"\"\"Report error rate on test_doc sentiments, using supplied model and train_docs\"\"\"\n",
    "\n",
    "    train_targets = [doc.sentiment for doc in train_set]\n",
    "    train_regressors = [test_model.docvecs[doc.tags[0]] for doc in train_set]\n",
    "    #train_regressors = sm.add_constant(train_regressors)\n",
    "    predictor = svc_predictor_from_data(train_targets, train_regressors)\n",
    "\n",
    "    test_regressors = [test_model.docvecs[doc.tags[0]] for doc in test_set]\n",
    "    #test_regressors = sm.add_constant(test_regressors)\n",
    "\n",
    "    # Predict & evaluate\n",
    "    pre_y = predictor.predict(test_regressors)\n",
    "    accuracy = accuracy_score(test_target, pre_y)\n",
    "    precision,recall,f1,support = precision_recall_fscore_support(test_target, pre_y)\n",
    "    return (accuracy, precision,recall,f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Doc2Vec(dbow,d100,n5,mc2,t12)\n",
      "\n",
      "Evaluating Doc2Vec(dbow,d100,n5,mc2,t12)\n",
      "accuracy: 0.6863213177369301 \n",
      "precision: [0.71303775 0.649529  ] \n",
      "recall: [0.73696763 0.62172732] \n",
      "F1: [0.72480523 0.63532416]\n",
      "============================================================\n",
      "Training Doc2Vec(\"alpha=0.05\",dm/m,d100,n5,w10,mc2,t12)\n",
      "\n",
      "Evaluating Doc2Vec(\"alpha=0.05\",dm/m,d100,n5,w10,mc2,t12)\n",
      "accuracy: 0.6615898782525662 \n",
      "precision: [0.69200925 0.61986185] \n",
      "recall: [0.71405451 0.59467681] \n",
      "F1: [0.70285906 0.60700821]\n",
      "============================================================\n",
      "Training Doc2Vec(dm/c,d100,n5,w5,mc2,t12)\n",
      "\n",
      "Evaluating Doc2Vec(dm/c,d100,n5,w5,mc2,t12)\n",
      "accuracy: 0.6299355454762473 \n",
      "precision: [0.66161575 0.58449558] \n",
      "recall: [0.69548552 0.54633351] \n",
      "F1: [0.67812798 0.56477062]\n",
      "============================================================\n",
      "\n",
      "Evaluating Doc2Vec(dbow,d100,n5,mc2,t12)+Doc2Vec(\"alpha=0.05\",dm/m,d100,n5,w10,mc2,t12)\n",
      "accuracy: 0.6692289329195512 \n",
      "precision: [0.69516548 0.63212255] \n",
      "recall: [0.72998296 0.59174362] \n",
      "F1: [0.71214891 0.61126697]\n",
      "============================================================\n",
      "\n",
      "Evaluating Doc2Vec(dbow,d100,n5,mc2,t12)+Doc2Vec(dm/c,d100,n5,w5,mc2,t12)\n",
      "accuracy: 0.6793029362616376 \n",
      "precision: [0.70669081 0.64146009] \n",
      "recall: [0.73143101 0.61281912] \n",
      "F1: [0.7188481 0.6268126]\n",
      "============================================================\n",
      "Wall time: 3h 25min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from random import shuffle\n",
    "shuffled_alldocs = alldocs[:]\n",
    "shuffle(shuffled_alldocs)\n",
    "for model in simple_models:\n",
    "    print(\"Training %s\" % model)\n",
    "    model.train(shuffled_alldocs, total_examples=len(shuffled_alldocs), epochs=model.epochs)\n",
    "\n",
    "    print(\"\\nEvaluating %s\" % model)\n",
    "    accuracy, precision,recall,f1 = error_rate_for_model(model, Steam_train, Steam_test,y_test)\n",
    "    #error_rates[str(model)] = err_rate\n",
    "    print('accuracy:',accuracy,'\\nprecision:',precision,'\\nrecall:',recall,'\\nF1:',f1)\n",
    "    print('='*60)\n",
    "\n",
    "for model in [models_by_name['dbow+dmm'], models_by_name['dbow+dmc']]:\n",
    "    print(\"\\nEvaluating %s\" % model)\n",
    "    accuracy, precision,recall,f1 = error_rate_for_model(model, Steam_train, Steam_test, y_test)\n",
    "    #error_rates[str(model)] = err_rate\n",
    "    print('accuracy:',accuracy,'\\nprecision:',precision,'\\nrecall:',recall,'\\nF1:',f1)\n",
    "    print('='*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
