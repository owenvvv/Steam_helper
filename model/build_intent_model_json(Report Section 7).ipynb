{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import codecs\n",
    "\n",
    "encoding = 'utf-8'\n",
    "\n",
    "file_location = \"../data/intent_queries.json\"\n",
    "file_stream = codecs.open(file_location, 'r', 'utf-8')\n",
    "jdata = json.load(file_stream)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_enc = {\n",
    "    'commonQ.assist':0,\n",
    "    'commonQ.how':1,\n",
    "    'commonQ.name':2,\n",
    "    'commonQ.wait':3,\n",
    "    'recommend.game':4,\n",
    "    'game.age':5,\n",
    "    'game.price':6,\n",
    "    'response.abusive':7,\n",
    "    'response.negative':8,\n",
    "    'response.incorrect':9,\n",
    "    'game.release_date':10,\n",
    "    'game.platforms':11,\n",
    "    'response.positive':12\n",
    "}\n",
    "\n",
    "intent_dec = {\n",
    "    0:'commonQ.assist',\n",
    "    1:'commonQ.how',\n",
    "    2:'commonQ.name',\n",
    "    3:'commonQ.wait',\n",
    "    4:'recommend.game',\n",
    "    5:'game.age',\n",
    "    6:'game.price',\n",
    "    7:'response.abusive',\n",
    "    8:'response.negative',\n",
    "    9:'response.incorrect',\n",
    "    10:'game.release_date',\n",
    "    11:'game.platforms',\n",
    "    12:'response.positive'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199\n"
     ]
    }
   ],
   "source": [
    "train_list = []\n",
    "for intent in jdata:\n",
    "    for data in jdata[intent]:\n",
    "        line=\"\"\n",
    "        for sequence in data['data']:\n",
    "            line += sequence['text']\n",
    "        train_list.append([line.lower(),intent_enc[intent]])\n",
    "print(len(train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Query  Intent\n",
      "0  need help please       0\n",
      "1             hello       0\n",
      "2                hi       0\n",
      "3         need help       0\n",
      "4  will you help me       0\n",
      "(199, 2)\n"
     ]
    }
   ],
   "source": [
    "trainDF = pd.DataFrame(train_list, columns=['Query','Intent'] )\n",
    "print(trainDF.head())\n",
    "print(trainDF.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "wnl = nltk.WordNetLemmatizer()\n",
    "from nltk.corpus import stopwords\n",
    "mystopwords=stopwords.words(\"english\")\n",
    "wnl = nltk.WordNetLemmatizer()\n",
    "\n",
    "import string\n",
    "string.punctuation\n",
    "\n",
    "print(mystopwords)\n",
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"can not \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    #tokens = nltk.word_tokenize(text)\n",
    "    #tokens=[ wnl.lemmatize(t.lower(),pos='v') for t in tokens]\n",
    "    #text=\" \".join(tokens)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    need help please\n",
       "1               hello\n",
       "2                  hi\n",
       "3           need help\n",
       "4    will you help me\n",
       "Name: Query, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF['Query'] = trainDF['Query'].map(lambda query : clean_text(query))\n",
    "trainDF['Query'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer,TfidfTransformer\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199, 195)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(trainDF.Query)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199, 195)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf-svm', SGDClassifier(loss='log', penalty='l2',\n",
    "                                          alpha=1e-3, max_iter=100, random_state=42)),\n",
    "])\n",
    "_ = text_clf_svm.fit(trainDF['Query'], trainDF['Intent'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "[[8 0 0]\n",
      " [0 2 0]\n",
      " [0 0 4]]\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           4       1.00      1.00      1.00         8\n",
      "           6       1.00      1.00      1.00         2\n",
      "           9       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00        14\n",
      "   macro avg       1.00      1.00      1.00        14\n",
      "weighted avg       1.00      1.00      1.00        14\n",
      "\n",
      "                                                Query  Intent  Predicted\n",
      "0   i am 10 years old and looking for free shootin...       4          4\n",
      "1   i am looking for killing game with animals for...       4          4\n",
      "2          any action game with animal under 10 bucks       4          4\n",
      "3                                        running game       4          4\n",
      "4                              airplane shooting game       4          4\n",
      "5   i am 10 and looking for free shooting zombie g...       4          4\n",
      "6                           any rpg game that is free       4          4\n",
      "7        multi player game shooting monsters and free       4          4\n",
      "8                          no this is not what i want       9          9\n",
      "9                                           not right       9          9\n",
      "10                                    not what i want       9          9\n",
      "11                                        not correct       9          9\n",
      "12                                   do i have to pay       6          6\n",
      "13                                           must pay       6          6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "testfile_location = \"../data/test_queries.json\"\n",
    "testfile_stream = codecs.open(testfile_location, 'r', 'utf-8')\n",
    "testjdata = json.load(testfile_stream)\n",
    "test_list = []\n",
    "for intent in testjdata:\n",
    "    for data in testjdata[intent]:\n",
    "        line=\"\"\n",
    "        for sequence in data['data']:\n",
    "            line += sequence['text']\n",
    "        test_list.append([line.lower(),intent_enc[intent]])\n",
    "print(len(test_list))\n",
    "testDF = pd.DataFrame(test_list, columns=['Query','Intent'])\n",
    "testDF['Query'] = testDF['Query'].map(lambda query : clean_text(query))\n",
    "predicted = text_clf_svm.predict(testDF.Query)\n",
    "print(metrics.confusion_matrix(testDF.Intent, predicted))\n",
    "print(np.mean(predicted == testDF.Intent) )\n",
    "print(metrics.classification_report(testDF.Intent, predicted))\n",
    "testDF['Predicted'] = predicted\n",
    "print(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(text_clf_svm, open('intent_SGDClassifier_v2.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query = ['Any action game that is free']\n",
    "testDF = pd.DataFrame(test_query, columns=['Query'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "[4]\n",
      "[[0.00850771 0.01114962 0.01329406 0.00741142 0.8160136  0.00895915\n",
      "  0.05152187 0.00921815 0.01237884 0.02831408 0.01410111 0.01031009\n",
      "  0.00882029]]\n",
      "recommend.game\n",
      "0.8160136032103338\n"
     ]
    }
   ],
   "source": [
    "intent_model_svm = pickle.load(open('intent_SGDClassifier_v2.pkl', 'rb'))\n",
    "result_svm = intent_model_svm.predict(testDF.Query)\n",
    "result_svm_proba = intent_model_svm.predict_proba(testDF.Query)\n",
    "print(intent_model_svm.classes_)\n",
    "print(result_svm)\n",
    "print(result_svm_proba)\n",
    "print(intent_dec[result_svm[0]])\n",
    "print(result_svm_proba[0][result_svm[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf_svm.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8160136032103338"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_classes = list(text_clf_svm.classes_)\n",
    "result_svm_proba[0][svc_classes.index(result_svm[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "4\n",
      "recommend.game\n",
      "0.8242869941635382\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "example_sent = [\"I am 10 years old and looking for free shooting game with zombies. Can you recommend\"]\n",
    "intent_model_svm = pickle.load(open('intent_SGDClassifier_v2.pkl', 'rb'))\n",
    "example_sentDF = pd.DataFrame(example_sent, columns=['Query'])\n",
    "predict = intent_model_svm.predict(example_sentDF.Query)\n",
    "predict_proba = intent_model_svm.predict_proba(example_sentDF.Query)\n",
    "print(intent_model_svm.classes_)\n",
    "print(predict[0])\n",
    "print(intent_dec[predict[0]])\n",
    "print(predict_proba[0][predict[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
